{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc01a3b7-c6e0-422e-93e6-bd71db33277e",
   "metadata": {},
   "source": [
    "# AI编程实操课"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d22b4f-6071-4ede-bf92-dade9bbe78a2",
   "metadata": {},
   "source": [
    "## 💡 这节课会带给你"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3678e7a-b40c-4b13-8b29-5241f253a5e2",
   "metadata": {},
   "source": [
    "1. 了解AI编程需要的工具\n",
    "2. 自己搭建一套Copilot\n",
    "3. 学会用AI编程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76ceec6-5060-42ca-a30a-36d43329a767",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>当你关闭视频的时候，可以自信的说，我会用AI编程了</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a0e3c8-a795-425e-a4ba-676bcca3b363",
   "metadata": {},
   "source": [
    "# 前置软件安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d223f2-36a4-40a0-a6b4-33a5aa7a8c09",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>上课要求：必须使用电脑</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb98158-a553-4838-b473-5a37cbdd8570",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de65f642-7e1e-488b-a1af-0907ab54849c",
   "metadata": {},
   "source": [
    "- 官方网页：\n",
    "  - https://www.python.org/\n",
    "  - 推荐版本：Python 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497b578-e809-475b-83d2-97238cb188cc",
   "metadata": {},
   "source": [
    "## Visual Studio Code (简称 VS Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a35a20-0762-45d6-8205-7a643643c009",
   "metadata": {},
   "source": [
    "- 官方网页：\n",
    "  - https://code.visualstudio.com/\n",
    "- VSCode Python插件\n",
    "  - https://marketplace.visualstudio.com/items?itemName=ms-python.python\n",
    "  - 解释：Python插件不是Python脚本解析器，是VSCode编辑器在编写Python脚本的时候，做语法检测、Debug调用的时候的小工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e8365-23cb-418f-b660-e692df57e574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d866301d-0862-4dcd-a0a3-93bace406423",
   "metadata": {},
   "source": [
    "# AI编程工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59a06c-10c1-4832-91f8-75d8ee4eefa8",
   "metadata": {},
   "source": [
    "## TONGYI Lingma\n",
    "- 官方地址： https://tongyi.aliyun.com/lingma\n",
    "- 通义灵码是阿里开发的支持 VSCode的的服务。\n",
    "- 收费情况：个人免费、企业版本收费\n",
    "- 模型服务：阿里提供代码生成模型服务\n",
    "- 便捷度：高 （用户只需要在VSCode中安装即可）\n",
    "- 插件安装地址：https://marketplace.visualstudio.com/items?itemName=Alibaba-Cloud.tongyi-lingma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca485d-6bcf-45dc-aa2c-a6b9359e1e1d",
   "metadata": {},
   "source": [
    "## 安装过程\n",
    "1. 在VSCode中查找\"TONGYI Lingma\"\n",
    "   \n",
    "<img src=\"images/tongyi_step1.PNG\" width=60%>\n",
    "\n",
    "2. 安装成功后，注册阿里云账号，登录TONGYI Lingma\n",
    "   \n",
    "<img src=\"images/tongyi_step2.PNG\" width=60%>\n",
    "\n",
    "3. 登录成功显示\n",
    "\n",
    "<img src=\"images/tongyi_step3.PNG\" width=60%>\n",
    "\n",
    "4. 新建文件，进入文件开始使用\n",
    "\n",
    "<img src=\"images/tongyi_step4.PNG\" width=60%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88f4b7-827b-43c7-8063-1e9d49f1f6f5",
   "metadata": {},
   "source": [
    "## 其他工具推荐\n",
    "### CodeGeex \n",
    "- 官方网页：https://codegeex.cn/\n",
    "- VSCode插件安装地址: https://marketplace.visualstudio.com/items?itemName=aminer.codegeex \n",
    "- 收费情况：目前免费\n",
    "- 制造商：智谱\n",
    "\n",
    "### Comate\n",
    "- 官方网页： https://comate.baidu.com/\n",
    "- VSCode插件安装地址： https://marketplace.visualstudio.com/items?itemName=BaiduComate.comate\n",
    "- 收费情况：免费\n",
    "- 制造商：百度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe00d2-5ece-4f7e-b55a-2e039d0e172b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：安装插件有两种方式：可以在VSCode的扩展中搜索安装，也可以点击上面的插件地址安装</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64db28d-fde8-4594-82d3-b5a3423850c5",
   "metadata": {},
   "source": [
    "# 搭建一个Github Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc2b2a-3eca-4e6b-8db4-9b70c3d88809",
   "metadata": {},
   "source": [
    "## 架构图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32654ab1-8f3d-4094-9984-dc0e51b26cd8",
   "metadata": {},
   "source": [
    "<img src=\"images/copilot_framework.png\" width=60%>\n",
    "\n",
    "使用本地化方案由3部分组成\n",
    "- 编辑器上的插件\n",
    "- 链接插件和模型的管理服务，类似：Tabby、Ollama、VLLM等\n",
    "- 代码生成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605d861-f1f4-434c-ac1e-dfb42593c9b1",
   "metadata": {},
   "source": [
    "## Tabby\n",
    "### Tabby介绍\n",
    "- 官方网页：https://tabby.tabbyml.com/\n",
    "- 如何安装：https://tabby.tabbyml.com/docs/quick-start/installation/apple/\n",
    "- 详细安装过程： https://agiclass.feishu.cn/docx/ClrVddclboshICxgMmgcOggMnU3#HMR6dsJe5olNE1xpPGKcS9t4n0e\n",
    "\n",
    "以下是部分内容，大家以以上的详细内容为主"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af7e9e-aacc-4745-9a68-137433aa9ac7",
   "metadata": {},
   "source": [
    "### Mac电脑安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96e8b0-ec39-4e26-8589-b5acce1899f0",
   "metadata": {},
   "source": [
    "1. 第一步：安装本地模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd31e5-4e66-4d3c-8778-508a19d8d3a5",
   "metadata": {},
   "source": [
    "```bash\n",
    "brew install tabbyml/tabby/tabby\n",
    "\n",
    "# Start server with StarCoder-1B\n",
    "tabby serve --device metal --model TabbyML/StarCoder-1B # 这里的模型可以根据你的环境和内存替换成你真实需要的模型\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b427766a-c8b6-42d7-b086-794d29078cdd",
   "metadata": {},
   "source": [
    "2. 第二步：安装客户端，这里以VSCode为例\n",
    "- 在VSCode中安装插件\n",
    "  \n",
    "<img src=\"images/tabby_step1.png\" width=60% />\n",
    "\n",
    "- 查看状态\n",
    "\n",
    "<img src=\"images/tabby_step2.png\" width=60% />\n",
    "\n",
    "- 修改配置\n",
    "\n",
    "<img src=\"images/tabby_step3.png\" width=60% />\n",
    "\n",
    "- 设置本地服务\n",
    "\n",
    "<img src=\"images/tabby_step4.png\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e7a2dc-fcd6-4a29-a1ba-edb49bce2ab0",
   "metadata": {},
   "source": [
    "#### Tabby 版本的问题\n",
    "- Tabby 目前还是在高速的开发迭代中，所以版本兼容需要测试，如果你安装不成功，未必是你的问题\n",
    "- Tabby 在0.5.2 以前的版本是不需要登录，也不需要token就可以正常使用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b7593-058d-4097-ab96-4e44a7a22f41",
   "metadata": {},
   "source": [
    "#### Tabby 根据不同版本安装\n",
    "\n",
    "- Docker 安装\n",
    "\n",
    "    ```docker pull tabbyml/tabby:0.5.2 #大家可以更具需要选择版本，低版本使用不了新模型 ``` \n",
    "\n",
    "- 命令行安装\n",
    "  - 直接到github上选择指定的版本下载\n",
    "  - https://github.com/TabbyML/tabby/releases \n",
    "\n",
    "  <img src=\"images/tabby_extra_1.png\" width=60% />\n",
    "  \n",
    "- 源码自行编译\n",
    "  - ```git clone https://github.com/TabbyML/tabby.git```\n",
    "  - Tabby 使用Rust作为后台管理，对于熟悉Rust的同学可以用Rust进行编译\n",
    "\n",
    "- 对于0.5.3 以后得版本的特殊说明\n",
    "  - 如何获得Token \n",
    "    \n",
    "  <img src=\"images/tabby_step5.png\" width=60% />\n",
    "\n",
    "  * 注意：这里的URL地址是你自己启动的 tabby 后端服务的地址\n",
    "  \n",
    "  - 如何填写Token\n",
    "  \n",
    "  <img src=\"images/tabby_step6.png\" width=60% />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dba47c-9ec2-4f64-99b2-b0ab6f3715cb",
   "metadata": {},
   "source": [
    "## Continue + Ollama方案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5501011-b303-40e2-94b2-048d3f3c3259",
   "metadata": {},
   "source": [
    "本方案的客户端和服务端分别由两个开源项目组成，客户端是 Continue，服务端是 Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed498a9-249e-4ae6-9efe-ed2c2a2e410e",
   "metadata": {},
   "source": [
    "### Ollama\n",
    "- 官方网页： https://ollama.com/ (因为模型本地化部署后续课程有详细介绍，这里不展开）\n",
    "- 开源地址： https://github.com/ollama/ollama\n",
    "- 操作系统： Windows、Linux、Mac\n",
    "- 操作命令流程：(以Linux为例）\n",
    "```bash\n",
    "$ curl -fsSL https://ollama.com/install.sh | sh  # 安装 Ollama管理端 \n",
    "$ export OLLAMA_HOST=0.0.0.0  # 如果希望服务可以被非本机的人访问\n",
    "$ ollama run llama3.1 #通过 Ollama 启动模型 这里我们可以用 llama3.1 用于chat对话\n",
    "$ ollama run deepseek-coder:6.7b-base  # 使用 deepseek-coder 作为编码生成模型\n",
    "```\n",
    "自此Ollama启动结束\n",
    "\n",
    "- 关于Ollama的架构、原理、本地化模型部署，在后面的课程都会详细讲解，这里大家简单了解即可\n",
    "- 更多参考资料 https://ollama.com/blog/continue-code-assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa2e321-a7e5-4835-b280-4fa2efaa2922",
   "metadata": {},
   "source": [
    "### Continue \n",
    "- 官方网页： https://www.continue.dev/\n",
    "- 支持平台： VS Code 和 JetBrains\n",
    "- VS扩展安装地址： https://marketplace.visualstudio.com/items?itemName=Continue.continue\n",
    "- 支持自定义配置后端模型和地址\n",
    "具体的操作步骤如下\n",
    "\n",
    "1. 安装Continue\n",
    "\n",
    "<img src=\"images/continue_step1.png\" width=60% />\n",
    "\n",
    "2. 打开配置\n",
    "\n",
    "<img src=\"images/continue_step2.png\" width=60% />\n",
    "\n",
    "3. 设置对应的服务\n",
    "\n",
    "<img src=\"images/continue_step3.png\" width=60% />\n",
    "\n",
    "配置JSON\n",
    "\n",
    "```\n",
    "  \"tabAutocompleteModel\": {\n",
    "    \"title\": \"DeepSeek Coder 6.7B\", \n",
    "    \"provider\": \"ollama\",\n",
    "    \"model\": \"deepseek-coder:6.7b-base\", # Ollama启动的模型\n",
    "    \"apiBase\": \"http://ifootoo.com:16666\" # Ollama启动的服务地址\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc9f18-1926-441b-b3df-67c9c203a70b",
   "metadata": {},
   "source": [
    "自此，基于Ollama + Continue的 编码 Copilot安装完成，可以在本地的客户端编写代码，可以像使用Lingma一样编程了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b466e-6405-4b1f-8b76-554cf2f18afb",
   "metadata": {},
   "source": [
    "## Github Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf3187-605d-47e5-8d94-6949dc1cb6c1",
   "metadata": {},
   "source": [
    "### 注意点\n",
    "- 登录：使用github的账号在 VSCode中登录\n",
    "- 快捷键： Cmd + I / Ctrl + I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ee3a3-6d83-4db9-80c8-4b8ebff60b6f",
   "metadata": {},
   "source": [
    "# 使用AI编程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f39437-321c-4dcc-89a5-37a78320fb58",
   "metadata": {},
   "source": [
    "## 任务\n",
    "- 需求：制作一个简单的客服机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c66b9c6-cdc0-4ad0-9b20-0b260d023550",
   "metadata": {},
   "source": [
    "## 操作\n",
    "使用Python实现一个调用GPT的服务、使用React或者Vue实现问答前端\n",
    "\n",
    "### 后端 （提示词列表）\n",
    "```\n",
    "1. 我是个小白，我需要制作一个简单的客服机器人 ，你有什么建议\n",
    "2. 如果我是个小白程序员，我怎么样规划这个客服机器人的架构呢？\n",
    "3. 我是小白程序员，那么这个问答的后端应该怎么设计？\n",
    "4. 那我选择 Flask这个架构，如何写这个后端，请直接出python的实现，我在mac 电脑上，请告诉我，怎么一步一步让这个代码运行起来。\n",
    "5. bash: /usr/local/bin/flask: /usr/local/opt/python@3.10/bin/python3.10: bad interpreter: No such file or directory\n",
    "6. GET 和 POST 到底是什么，应该怎么理解\n",
    "7. Access to fetch at 'http://127.0.0.1:5000/query' from origin 'http://localhost:8081' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource. If an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with CORS disabled.  flask 如何解决这个问题，请给出具体的修改方案\n",
    "8. 如果我想部署到云端，应该怎么弄？\n",
    "9.\n",
    "    from flask import Flask, request, jsonify\n",
    "    from flask_cors import CORS\n",
    "    app = Flask(__name__)\n",
    "    CORS(app)  # 应用CORS到所有路由\n",
    "    \n",
    "    \n",
    "    # 导入依赖库\n",
    "    from openai import OpenAI\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "    \n",
    "    # 加载 .env 文件中定义的环境变量\n",
    "    _ = load_dotenv(find_dotenv())\n",
    "    \n",
    "    # 初始化 OpenAI 客户端\n",
    "    client = OpenAI()  # 默认使用环境变量中的 OPENAI_API_KEY 和 OPENAI_BASE_URL\n",
    "    \n",
    "    # 示例问答数据，用于模拟简单的问答逻辑\n",
    "    faq_data = {\n",
    "        \"what is your name\": \"My name is Bot.\",\n",
    "        \"how are you\": \"I am fine, thank you!\",\n",
    "    }\n",
    "    \n",
    "    # 基于 prompt 生成文本\n",
    "    # 默认使用 gpt-4o-mini 模型\n",
    "    def get_completion(prompt, response_format=\"text\", model=\"gpt-4o-mini\"):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]    # 将 prompt 作为用户输入\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.7,                                  # 模型输出的随机性，0 表示随机性最小\n",
    "            # 返回消息的格式，text 或 json_object\n",
    "            response_format={\"type\": response_format},\n",
    "        )\n",
    "        return response.choices[0].message.content          # 返回模型生成的文本\n",
    "    \n",
    "    \n",
    "    @app.route('/query', methods=['POST'])\n",
    "    def answer_query():\n",
    "        data = request.json  # 获取JSON请求数据\n",
    "        user_query = data.get(\"query\").lower().strip()  # 提取用户问题并格式化\n",
    "        # 根据用户问题在FAQ数据中查找答案\n",
    "    \n",
    "        answer = get_completion(user_query)  # 调用 get_completion 函数生成文本\n",
    "        #answer = faq_data.get(user_query, \"Sorry, I do not understand the question.\")\n",
    "        return jsonify({'answer': answer})\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        app.run(debug=True)\n",
    "# 在调试模式下运行应用  根据以上代码，如何添加历史记录保存和读取，包括数据库设计\n",
    "\n",
    "10. 如何添加一个接口，让这个openai 的接口请求本地的Ollama 大模型 \n",
    "11. 如何用阿里云部署这个客服程序，请给出详细的步骤\n",
    "```\n",
    "\n",
    "- 完整的问答对话全文： https://chatgpt.com/share/dad50d7d-6f6a-4657-b2bd-80c3847ff6fb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c693a1a2-0c9b-4c99-99e6-aa213d598072",
   "metadata": {},
   "source": [
    "### 前端\n",
    "```\n",
    "1. 我是小白程序员，我需要实现一个简单的客户对话窗口，你觉得客服窗口应该是啥样的？\n",
    "2. 能否画一个前端试试\n",
    "3. 我是个前端的小白，如何实现上面的UI，有什么框架可以使用\n",
    "4. 如果选择Vue的框架，如何实现，请给出具体的步骤\n",
    "5. 我们要访问的 api 如下url = \"http://127.0.0.1:5000/query\"\n",
    "    payload = json.dumps({\n",
    "      \"query\": \"what is your name\"\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json'\n",
    "    }   如何将 前端的输入和后端的请求对上\n",
    "\n",
    "6. {\n",
    "    \"answer\": \"I’m called ChatGPT. How can I assist you today?\"\n",
    "}  返回的结果如上，需要前端做解析\n",
    "\n",
    "```\n",
    "因为有图的原因，前端的全文无法共享。截图放置在8期的飞书网页上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abcd2b-91ad-414f-b703-03055cb8b67f",
   "metadata": {},
   "source": [
    "## 本地编写一个Qt程序\n",
    "提示词\n",
    "\n",
    "```\n",
    "1. 请用PyQt 写一个计算器， 上面是显示部分，下面是1-9，还有加减乘除和等号，请给出具体的代码和执行步骤\n",
    "2. NameError: name 'Qt' is not defined\n",
    "3. from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QPushButton, QLineEdit  这行代码什么意思，给我详细的解释\n",
    "```\n",
    "问答全文链接 https://chatgpt.com/share/ec05657c-b08d-49f7-9c6c-5ff4f723115c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b85bab6-47ee-4cb2-81d6-af4b375e818a",
   "metadata": {},
   "source": [
    "# 本期代码\n",
    "- [8 期：AI 编程工具与演示笔记](https://agiclass.feishu.cn/docx/ScE4dmmRpo3gSSxfO5OcJDXsnoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be9b4c-dbed-4e24-aa7b-286142d4febb",
   "metadata": {},
   "source": [
    "# 往期内容参考\n",
    "- [5 期：AI 编程工具与演示笔记](https://agiclass.feishu.cn/docx/ClrVddclboshICxgMmgcOggMnU3)\n",
    "- [6 期：AI 编程工具与演示笔记](https://agiclass.feishu.cn/docx/FQG5dbeCqo4UjAxXKgucrWmgn9f)\n",
    "- [7 期：AI 编程工具与演示笔记](https://agiclass.feishu.cn/docx/CVSSdwjctonP6QxRraocBRSpnkg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
